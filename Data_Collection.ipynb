{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097518fa-b228-4714-8cf4-d352f0e54fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical exchange rate data saved to currency_exchange_rate.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "api_key = \"1WD02A0ZXUENB863\" #Alpha Vantage\n",
    "\n",
    "from_currency = \"USD\"\n",
    "to_currency = \"INR\"\n",
    "url = f\"https://www.alphavantage.co/query?function=FX_DAILY&from_symbol={from_currency}&to_symbol={to_currency}&apikey={api_key}&outputsize=full\"\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Extract historical data\n",
    "time_series = data.get(\"Time Series FX (Daily)\", {})\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_file = \"currency_exchange_rate.csv\"\n",
    "\n",
    "# Save data to a CSV file\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Date\", \"Exchange Rate (USD/INR)\"])\n",
    "    for date, daily_data in time_series.items():\n",
    "        exchange_rate = daily_data.get(\"4. close\", \"\")\n",
    "        writer.writerow([date, exchange_rate])\n",
    "\n",
    "print(f\"Historical exchange rate data saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d5f104-4b27-4179-9641-c76851dfc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date conversion completed and saved to the same CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mapping quarters to months\n",
    "quarter_to_month = {\n",
    "    \"Q1\": \"04\",  \n",
    "    \"Q2\": \"07\",  \n",
    "    \"Q3\": \"10\",  \n",
    "    \"Q4\": \"01\"   # next year\n",
    "}\n",
    "\n",
    "file_path = \"gdp_growth_rates.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def convert_to_date(fy_quarter):\n",
    "    fy, quarter = fy_quarter.split(\" (\")\n",
    "    fy_start = int(fy.split(\"-\")[0])\n",
    "    month = quarter_to_month[quarter.strip(\")\")]\n",
    "\n",
    "    year = fy_start if month != \"01\" else fy_start + 1\n",
    "    return f\"{year}-{month}-01\"  \n",
    "\n",
    "df[\"Date\"] = df[\"Year\"].apply(convert_to_date)\n",
    "\n",
    "df.drop(columns=[\"Year\"], inplace=True)\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Date conversion completed and saved to the same CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1070d782-0bf1-4a7b-b6f1-b29943b2249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to gdp_growth_rates.csv\n"
     ]
    }
   ],
   "source": [
    "#merge usa and india gdp growth rated into one file \n",
    "import pandas as pd\n",
    "\n",
    "india_file = \"datasets/gdp_growth_rates_india.csv\"\n",
    "usa_file = \"datasets/gdp_growth_rates_usa.csv\"\n",
    "merged_file = \"gdp_growth_rates.csv\"\n",
    "\n",
    "india_df = pd.read_csv(india_file)\n",
    "usa_df = pd.read_csv(usa_file)\n",
    "\n",
    "india_df[\"Date\"] = pd.to_datetime(india_df[\"Date\"], format=\"%d-%m-%Y\")\n",
    "usa_df[\"Date\"] = pd.to_datetime(usa_df[\"observation_date\"], dayfirst=True)  # Set dayfirst=True for DD-MM-YYYY format\n",
    "\n",
    "india_df.rename(columns={\"Real GDP Growth Rate India\": \"GDP Rate India\"}, inplace=True)\n",
    "usa_df.rename(columns={\"A191RL1Q225SBEA\": \"GDP Rate USA\"}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(india_df[[\"Date\", \"GDP Rate India\"]], usa_df[[\"Date\", \"GDP Rate USA\"]], on=\"Date\", how=\"outer\")\n",
    "\n",
    "merged_df.sort_values(by=\"Date\", inplace=True)\n",
    "\n",
    "merged_df.to_csv(merged_file, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {merged_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e736d905-6677-4032-9dd4-2068e20e16a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data has been saved to interest_rates.csv.\n"
     ]
    }
   ],
   "source": [
    "#merge usa and india interest rates into one file\n",
    "import pandas as pd\n",
    "\n",
    "usa_file = \"datasets/interest_rates_usa.csv\"\n",
    "india_file = \"datasets/interest_rates_india.csv\"\n",
    "merged_file = \"interest_rates.csv\"\n",
    "\n",
    "usa_df = pd.read_csv(usa_file)\n",
    "india_df = pd.read_csv(india_file)\n",
    "\n",
    "usa_df[\"observation_date\"] = pd.to_datetime(usa_df[\"observation_date\"], format=\"%Y-%m-%d\")\n",
    "india_df[\"observation_date\"] = pd.to_datetime(india_df[\"observation_date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "merged_df = pd.merge(usa_df, india_df, on=\"observation_date\", how=\"inner\")\n",
    "\n",
    "merged_df.rename(\n",
    "    columns={\n",
    "        \"FEDFUNDS\": \"Interest Rate USA\",\n",
    "        \"IRSTCI01INM156N\": \"Interest Rate India\"\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "merged_df.to_csv(merged_file, index=False)\n",
    "\n",
    "print(f\"Merged data has been saved to {merged_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9193d622-f034-43e4-8ca5-c35b63dae453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date format updated successfully and saved to the same file.\n"
     ]
    }
   ],
   "source": [
    "#converting into standard date format\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"trade_balance.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df['Month'] = pd.to_datetime(df['Month'], format='%b-%y').dt.strftime('%Y-%m-01')\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Date format updated successfully and saved to the same file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eaae53b-594c-449d-9e7e-99edadb17759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "# from nsetools import Nse\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# nse = Nse()\n",
    "\n",
    "# def fetch_nifty_50_live():\n",
    "#     try:\n",
    "#         index_data = nse.get_index_quote(\"nifty 50\")\n",
    "#         current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#         data = {\n",
    "#             \"Date\": [current_date],\n",
    "#             \"Index\": [index_data['indexName']],\n",
    "#             \"Current Value\": [index_data['lastPrice']],\n",
    "#             \"Change\": [index_data['change']],\n",
    "#             \"Change (%)\": [index_data['pChange']]\n",
    "#         }\n",
    "\n",
    "#         df = pd.DataFrame(data)\n",
    "#         file_name = \"NIFTY_50_Live_Data.csv\"\n",
    "#         df.to_csv(file_name, index=False, mode='a', header=not bool(pd.read_csv(file_name).shape[0]))\n",
    "#         print(f\"NIFTY 50 live data saved to {file_name}.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "\n",
    "# fetch_nifty_50_live()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7932f409-1898-4bbf-81a4-58167f532536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nsetools\n",
      "  Downloading nsetools-2.0.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: six in c:\\users\\blah9\\appdata\\roaming\\python\\python311\\site-packages (from nsetools) (1.16.0)\n",
      "Collecting dateutils (from nsetools)\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\blah9\\anaconda3\\lib\\site-packages (from nsetools) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\blah9\\appdata\\roaming\\python\\python311\\site-packages (from dateutils->nsetools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in c:\\users\\blah9\\anaconda3\\lib\\site-packages (from dateutils->nsetools) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\blah9\\anaconda3\\lib\\site-packages (from requests->nsetools) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\blah9\\anaconda3\\lib\\site-packages (from requests->nsetools) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\blah9\\anaconda3\\lib\\site-packages (from requests->nsetools) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\blah9\\anaconda3\\lib\\site-packages (from requests->nsetools) (2024.2.2)\n",
      "Downloading nsetools-2.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
      "Installing collected packages: dateutils, nsetools\n",
      "Successfully installed dateutils-0.6.12 nsetools-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install nsetools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51439e6d-f48e-420a-9a51-430b6095cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged 11 files into 'nifty_merged.csv'\n"
     ]
    }
   ],
   "source": [
    "#we have different csv files for different years with nifty 50 data\n",
    "#concatenating them together\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"./datasets/\"\n",
    "\n",
    "csv_files = sorted([f for f in os.listdir(directory) if f.startswith(\"NIFTY\") and f.endswith(\".csv\")])\n",
    "\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"./datasets/nifty_merged.csv\", index=False)\n",
    "\n",
    "print(f\"Successfully merged {len(csv_files)} files into 'nifty_merged.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f14f74b9-17c5-4241-b785-3be99893375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully merged files into 'stock_price_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nifty_df = pd.read_csv(\"datasets/nifty_merged.csv\")  \n",
    "sp500_df = pd.read_csv(\"datasets/s&p500.csv\")  \n",
    "\n",
    "nifty_df.columns = nifty_df.columns.str.strip()\n",
    "sp500_df.columns = sp500_df.columns.str.strip()\n",
    "\n",
    "merged_df = pd.merge(nifty_df, sp500_df, on=\"Date\", how=\"inner\")\n",
    "\n",
    "merged_df.rename(columns={\"Closed_x\": \"NIFTY\", \"Closed_y\": \"S&P500\"}, inplace=True)\n",
    "\n",
    "merged_df.to_csv(\"stock_price_data.csv\", index=False)\n",
    "\n",
    "print(\"Successfully merged files into 'stock_price_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59e86ca4-a299-4fba-83cb-689dc840ba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to 'inflation_rates.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "india_df = pd.read_csv(\"datasets/inflation_rates_india.csv\")\n",
    "us_df = pd.read_csv(\"datasets/inflation_rates_us.csv\")\n",
    "\n",
    "india_df_long = india_df.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name=\"Inflation_Rate_India\")\n",
    "us_df_long = us_df.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name=\"Inflation_Rate_US\")\n",
    "\n",
    "merged_df = pd.merge(india_df_long, us_df_long, on=[\"Year\", \"Month\"], how=\"outer\")\n",
    "\n",
    "month_map = {\n",
    "    \"Jan\": \"01\", \"Feb\": \"02\", \"Mar\": \"03\", \"Apr\": \"04\",\n",
    "    \"May\": \"05\", \"Jun\": \"06\", \"Jul\": \"07\", \"Aug\": \"08\",\n",
    "    \"Sep\": \"09\", \"Oct\": \"10\", \"Nov\": \"11\", \"Dec\": \"12\"\n",
    "}\n",
    "merged_df[\"Month\"] = merged_df[\"Month\"].map(month_map)\n",
    "\n",
    "merged_df[\"Date\"] = merged_df[\"Year\"].astype(str) + \"-\" + merged_df[\"Month\"] + \"-01\"\n",
    "\n",
    "final_df = merged_df[[\"Date\", \"Inflation_Rate_India\", \"Inflation_Rate_US\"]]\n",
    "\n",
    "final_df = final_df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "final_df.to_csv(\"inflation_rates.csv\", index=False)\n",
    "\n",
    "print(\"Merged data saved to 'inflation_rates.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f8028f1-48db-4495-87d1-dcb87c52fec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  US_Unemployment_Rate\n",
      "804 2015-01-01                   5.7\n",
      "805 2015-02-01                   5.5\n",
      "806 2015-03-01                   5.4\n",
      "807 2015-04-01                   5.4\n",
      "808 2015-05-01                   5.6\n"
     ]
    }
   ],
   "source": [
    "from fredapi import Fred\n",
    "import pandas as pd\n",
    "\n",
    "fred = Fred(api_key='aadcef49fb39a772a54e92142ac7f12c') #fred API Key\n",
    "\n",
    "us_unemployment = fred.get_series('UNRATE')\n",
    "\n",
    "us_unemployment_df = us_unemployment.to_frame(name='US_Unemployment_Rate')\n",
    "us_unemployment_df.index.name = 'Date'\n",
    "us_unemployment_df.reset_index(inplace=True)\n",
    "\n",
    "us_unemployment_df['Date'] = pd.to_datetime(us_unemployment_df['Date'])\n",
    "filtered_data = us_unemployment_df[(us_unemployment_df['Date'] >= '2015-01-01') & (us_unemployment_df['Date'] <= '2025-03-01')]\n",
    "\n",
    "print(filtered_data.head())\n",
    "\n",
    "filtered_data.to_csv('datasets/US_Unemployment_Rate.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0717b619-31e9-483b-a6eb-4850347d4fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged file saved as unemployment_rate.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = \"datasets/India_Unemployment_Rate.csv\"  \n",
    "file2 = \"datasets/US_Unemployment_Rate.csv\"  \n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "\n",
    "merged_df = pd.merge(df1, df2, on='Date', how='outer') \n",
    "\n",
    "output_file = \"unemployment_rate.csv\"\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Merged file saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de88d4-45b6-4a51-bcb9-a46a0c94c024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
